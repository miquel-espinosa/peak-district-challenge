{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## See main notebook for import & data loading etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch CNN model:\n",
    "- Resource 1: UNet (https://github.com/milesial/Pytorch-UNet)\n",
    "- Resource 2: Pytorch pretrained (only Resnet): https://pytorch.org/vision/stable/models.html and https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html (https://debuggercafe.com/semantic-segmentation-using-pytorch-fcn-resnet/)\n",
    "- Resource 3: SM pretrained: https://github.com/qubvel/segmentation_models.pytorch\n",
    "- Resource 4: https://medium.com/@mhamdaan/multi-class-semantic-segmentation-with-u-net-pytorch-ee81a66bba89 and https://github.com/hamdaan19/UNet-Multiclass\n",
    "\n",
    "\n",
    "#### Resource 1 (torch hub):\n",
    "- Odd output format (2 classes). Not sure how to fix this, perhaps model is not flexible enough to be adapted for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = torch.hub.load('milesial/Pytorch-UNet', 'unet_carvana', pretrained=True, scale=0.5)\n",
    "resource = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resource 2 (torchvision models):\n",
    "- No UNet available, so have not tried this model yet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = torchvision.models.resnet50(weights='IMAGENET1K_V2')  # use pretrained weights, see docs\n",
    "# res_weights = resnet.parameters\n",
    "resource = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resource 3 (SMP):\n",
    "- This model is currently used in main notebook. This is just the same but without PL wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input_bands = im_train.shape[1]\n",
    "# n_classes = len(np.unique(mask_test))  # already defined by return of histogram (takes few seconds to compute)\n",
    "\n",
    "unet_sm = smp.Unet(encoder_name=\"resnet50\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                   encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization or None\n",
    "                   in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "                   classes=n_classes,                      # model output channels (number of classes in your dataset)\n",
    "                   activation='softmax')  # activation function to apply after final convolution; One of [sigmoid, softmax, logsoftmax, identity, callable, None]\n",
    "resource = 3\n",
    "preprocessing_func = smp.encoders.get_preprocessing_fn('resnet50', pretrained='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resource == 3:\n",
    "    ## Use model like this:\n",
    "    \n",
    "    curr_model = unet_sm\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()  # see SMP for better loss functions (multiclass types)\n",
    "    optimizer = optim.SGD(curr_model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    for it, data in enumerate(train_dl, 0):\n",
    "        ## it: iteration, data is list of [train_ds, test_ds]\n",
    "        # print(it, data[1].shape)\n",
    "        pass \n",
    "\n",
    "    print(data[0].shape)\n",
    "    tmp = curr_model(data[0])\n",
    "    lca.print_info_ds(data[0])\n",
    "    lca.print_info_ds(data[1])\n",
    "    lca.print_info_ds(tmp)\n",
    "\n",
    "    criterion(tmp, data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource 4 (SMP via PL)\n",
    "- Writing a wrapper of the SMP model in PL\n",
    "\n",
    "**See main notebook**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('geo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fff134636c4dc08640ae6a35698a477c72623cae97fdeaa639b1241267bdf5e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
